{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kuXWMhmR1rU5"},"outputs":[],"source":["# Taken from https://github.com/Kulbear/deep-learning-nano-foundation/blob/master/mnist/Handwritten%20Digit%20Recognition%20with%20TFLearn.ipynb with some modifications"]},{"cell_type":"markdown","metadata":{"id":"RVqbq4K3yYUm"},"source":["# Handwritten Number Recognition with TFLearn and MNIST\n","\n","In this notebook, we'll be building a neural network that recognizes handwritten numbers 0-9. \n","\n","This kind of neural network is used in a variety of real-world applications including: recognizing phone numbers and sorting postal mail by address. To build the network, we'll be using the **MNIST** data set, which consists of images of handwritten numbers and their correct labels 0-9.\n","\n","We'll be using [TFLearn](http://tflearn.org/), a high-level library built on top of TensorFlow to build the neural network. We'll start off by importing all the modules we'll need, then load the data, and finally build the network."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3335,"status":"ok","timestamp":1644055773798,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"zWxET2vyyfcd","outputId":"fbee30dc-ef8d-4a8e-ecbf-9d191f096cbc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tflearn in /usr/local/lib/python3.7/dist-packages (0.5.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n"]}],"source":["!pip install tflearn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3087,"status":"ok","timestamp":1644055786468,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"KmUDwG492v2y","outputId":"39919198-046f-4603-cce6-dc209298cd5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3364,"status":"ok","timestamp":1644055781743,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"I_ZQi0L7yYUu","outputId":"f22ab6e7-f28f-40ca-b706-ec3174fe83e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}],"source":["# Import Numpy, TensorFlow, TFLearn, and MNIST data\n","import numpy as np\n","import tensorflow as tf\n","import tflearn\n","import tflearn.datasets.mnist as mnist"]},{"cell_type":"markdown","metadata":{"id":"IyqLdQTRyYUx"},"source":["## Retrieving training and test data\n","\n","The MNIST data set already contains both training and test data. There are 55,000 data points of training data, and 10,000 points of test data.\n","\n","Each MNIST data point has:\n","1. an image of a handwritten digit and \n","2. a corresponding label (a number 0-9 that identifies the image)\n","\n","We'll call the images, which will be the input to our neural network, **X** and their corresponding labels **Y**.\n","\n","We're going to want our labels as *one-hot vectors*, which are vectors that holds mostly 0's and one 1. It's easiest to see this in a example. As a one-hot vector, the number 0 is represented as [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], and 4 is represented as [0, 0, 0, 0, 1, 0, 0, 0, 0, 0].\n","\n","### Flattened data\n","\n","For this example, we'll be using *flattened* data or a representation of MNIST images in one dimension rather than two. So, each handwritten number image, which is 28x28 pixels, will be represented as a one dimensional array of 784 pixel values. \n","\n","Flattening the data throws away information about the 2D structure of the image, but it simplifies our data so that all of the training data can be contained in one array whose shape is [55000, 784]; the first dimension is the number of training images and the second dimension is the number of pixels in each image. This is the kind of data that is easy to analyze using a simple neural network."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":629,"status":"ok","timestamp":1644055791397,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"qkKEbjvZyYUz","outputId":"9e6a1348-ab6e-45cb-e6e2-1d581ed471e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Extracting mnist/train-images-idx3-ubyte.gz\n","Extracting mnist/train-labels-idx1-ubyte.gz\n","Extracting mnist/t10k-images-idx3-ubyte.gz\n","Extracting mnist/t10k-labels-idx1-ubyte.gz\n"]}],"source":["# Retrieve the training and test data\n","trainX, trainY, testX, testY = mnist.load_data(one_hot=True)"]},{"cell_type":"markdown","metadata":{"id":"2sW7hFVJyYU1"},"source":["## Visualize the training data\n","\n","Provided below is a function that will help you visualize the MNIST data. By passing in the index of a training example, the function `show_digit` will display that training image along with it's corresponding label in the title."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1644055795703,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"Rsp8_AoHyYU2","outputId":"57796c73-0104-47fc-efcd-20d37ae8c8f6"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Visualizing the data\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Function for displaying a training image by it's index in the MNIST set\n","def display_digit(index):\n","    label = trainY[index].argmax(axis=0)\n","    # Reshape 784 array into 28x28 image\n","    image = trainX[index].reshape([28,28])\n","    plt.title('Training data, index: %d,  Label: %d' % (index, label))\n","    plt.imshow(image, cmap='gray_r')\n","    plt.show()\n","    \n","# Display the first (index 0) training image\n","display_digit(100)"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"H1JGcz7hyYU4"},"source":["## Building the network\n","\n","TFLearn lets you build the network by defining the layers in that network. \n","\n","For this example, you'll define:\n","\n","1. The input layer, which tells the network the number of inputs it should expect for each piece of MNIST data. \n","2. Hidden layers, which recognize patterns in data and connect the input to the output layer, and\n","3. The output layer, which defines how the network learns and outputs a label for a given image.\n","\n","Let's start with the input layer; to define the input layer, you'll define the type of data that the network expects. For example,\n","\n","```\n","net = tflearn.input_data([None, 100])\n","```\n","\n","would create a network with 100 inputs. The number of inputs to your network needs to match the size of your data. For this example, we're using 784 element long vectors to encode our input data, so we need **784 input units**.\n","\n","\n","### Adding layers\n","\n","To add new hidden layers, you use \n","\n","```\n","net = tflearn.fully_connected(net, n_units, activation='ReLU')\n","```\n","\n","This adds a fully connected layer where every unit (or node) in the previous layer is connected to every unit in this layer. The first argument `net` is the network you created in the `tflearn.input_data` call, it designates the input to the hidden layer. You can set the number of units in the layer with `n_units`, and set the activation function with the `activation` keyword. You can keep adding layers to your network by repeated calling `tflearn.fully_connected(net, n_units)`. \n","\n","Then, to set how you train the network, use:\n","\n","```\n","net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n","```\n","\n","Again, this is passing in the network you've been building. The keywords: \n","\n","* `optimizer` sets the training method, here stochastic gradient descent\n","* `learning_rate` is the learning rate\n","* `loss` determines how the network error is calculated. In this example, with categorical cross-entropy.\n","\n","Finally, you put all this together to create the model with `tflearn.DNN(net)`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gndzI3G8yYU5"},"outputs":[],"source":["# Define the neural network\n","def build_model():\n","    # Inputs\n","    net = tflearn.input_data([None, trainX.shape[1]])\n","\n","    # Hidden layer(s)\n","    net = tflearn.fully_connected(net, 160, activation='ReLU')\n","    net = tflearn.fully_connected(net, 64, activation='ReLU')\n","    \n","    # Output layer and training model\n","    net = tflearn.fully_connected(net, 10, activation='softmax')\n","    net = tflearn.regression(net, optimizer='sgd', learning_rate=0.01, loss='categorical_crossentropy')\n","    \n","    model = tflearn.DNN(net)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1644055804790,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"BlA4MP0DyYU6","outputId":"081aec56-dc7b-4653-ca74-4174c3f9d763"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"]}],"source":["# Build the model\n","model = build_model()"]},{"cell_type":"markdown","metadata":{"id":"6bhiiTD9yYU9"},"source":["## Training the network\n","\n","Now that we've constructed the network, saved as the variable `model`, we can fit it to the data. Here we use the `model.fit` method. You pass in the training features `trainX` and the training targets `trainY`. Below I set `validation_set=0.1` which reserves 10% of the data set as the validation set. You can also set the batch size and number of epochs with the `batch_size` and `n_epoch` keywords, respectively.\n","\n","Too few epochs don't effectively train your network, and too many take a long time to execute. Choose wisely!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8786,"status":"ok","timestamp":1644055823896,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"ZPyMjdi1yYU-","outputId":"3b3a0fa8-d1ea-4521-e804-e367513fca6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Step: 494  | total loss: \u001b[1m\u001b[32m2.29701\u001b[0m\u001b[0m | time: 4.940s\n","| SGD | epoch: 001 | loss: 2.29701 - acc: 0.1180 -- iter: 49400/49500\n","Training Step: 495  | total loss: \u001b[1m\u001b[32m2.29683\u001b[0m\u001b[0m | time: 6.003s\n","| SGD | epoch: 001 | loss: 2.29683 - acc: 0.1192 | val_loss: 2.29773 - val_acc: 0.1096 -- iter: 49500/49500\n","--\n"]}],"source":["# Training\n","model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=100, n_epoch=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":477,"status":"ok","timestamp":1644055847214,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"vHfB5GY-yYU-","outputId":"b79aa93b-5235-4fb1-e727-9d8a15757a27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy:  0.1135\n"]}],"source":["# Compare the labels that our model predicts with the actual labels\n","\n","# Find the indices of the most confident prediction for each item. That tells us the predicted digit for that sample.\n","predictions = np.array(model.predict(testX)).argmax(axis=1)\n","\n","# Calculate the accuracy, which is the percentage of times the predicated labels matched the actual labels\n","actual = testY.argmax(axis=1)\n","test_accuracy = np.mean(predictions == actual, axis=0)\n","\n","# Print out the result\n","print(\"Test accuracy: \", test_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1430,"status":"ok","timestamp":1644056015934,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"lCO5DS-7Gj9R","outputId":"7907ff07-af00-40c1-c506-6279d5fed879"},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:/content/drive/MyDrive/Colab Notebooks/model/model.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"]}],"source":["# Optionally save model if we want to request it again in the future\n","model.save('/content/drive/MyDrive/Colab Notebooks/model/model.tfl')"]},{"cell_type":"markdown","metadata":{"id":"pwGGhOjvyYVC"},"source":["## Testing\n","After you're satisified with the training output and accuracy, you can then run the network on the **test data set** to measure it's performance! Remember, only do this after you've done the training and are satisfied with the results.\n","\n","A good result will be **higher than 95% accuracy**. Some simple models have been known to get up to 99.7% accuracy!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":425,"status":"ok","timestamp":1644039385343,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"OwPvCiuLyYVE","outputId":"baf7e93d-77ff-4b90-e8e5-b9d03e20313b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[7 2 1 ... 4 5 6] [7 2 1 ... 4 5 6]\n","Test accuracy:  0.9753\n"]}],"source":["# Compare the labels that our model predicts with the actual labels\n","\n","# Find the indices of the most confident prediction for each item. That tells us the predicted digit for that sample.\n","predictions = np.array(model.predict(testX)).argmax(axis=1)\n","\n","# Calculate the accuracy, which is the percentage of times the predicated labels matched the actual labels\n","actual = testY.argmax(axis=1)\n","test_accuracy = np.mean(predictions == actual, axis=0)\n","\n","# Print out the result\n","print(\"Test accuracy: \", test_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":583,"status":"ok","timestamp":1644056247693,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"IYetiV0bfVTV","outputId":"4eb55321-358e-4304-bbdd-fd37ad970336"},"outputs":[{"name":"stdout","output_type":"stream","text":["hasil 1\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Test for certain image\n","plt.imshow(testX[15].reshape((28,28)), cmap='gray_r')\n","print('Result', model.predict([testX[15].reshape(784)]).argmax(axis=1)[0].item())\n","\n"]},{"cell_type":"markdown","source":["## Deploy Model\n","\n","We try to deploy our model to be used on a backend. We use Flask as a framework to build backend API and also additionally setup [Ngrok](https://ngrok.com/). Ngrok is used to make it possible to expose our backend app to the internet and make it accessible from anywhere in the world. Note that after running the final script, you need to copy paste the Ngrok generated link (second link) instead the normal link (first link) to any frontend which will become part of your app (in our app, it will be the index.html file).\n"],"metadata":{"id":"zshT9snjvkzN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6981,"status":"ok","timestamp":1644056390628,"user":{"displayName":"Habib Rosyad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13938041707764114611"},"user_tz":-420},"id":"R9EaLXR7ZXz9","outputId":"89d2a81d-e831-4827-83c7-2830efa2547c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n","Collecting flask_cors\n","  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.7/dist-packages (from flask_cors) (1.1.4)\n","Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask_cors) (1.15.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (2.11.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.9->flask_cors) (2.0.1)\n","Installing collected packages: flask-cors\n","Successfully installed flask-cors-3.0.10\n"]}],"source":["!pip install flask-ngrok\n","!pip install flask_cors"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"4c0nJtinZnb9","outputId":"c8245201-9e67-4f3f-f2e1-9ab5f75d4cc6"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":[" * Running on http://25bd-35-231-86-172.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"name":"stderr","output_type":"stream","text":["127.0.0.1 - - [05/Feb/2022 10:25:35] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"]}],"source":["# Code taken from https://github.com/T-K-233/Recognize-Handwritten-Alphabet with some modifications\n","from flask import Flask, request, jsonify\n","from skimage import transform\n","from matplotlib import pyplot as plt\n","from flask_ngrok import run_with_ngrok\n","from flask_cors import CORS, cross_origin\n","from imageio import imread\n","import io\n","import base64\n","\n","app = Flask(__name__)\n","cors = CORS(app)\n","run_with_ngrok(app)\n","\n","# http://localhost:8000/predict\n","@app.route(\"/predict\", methods=['POST'])\n","@cross_origin()\n","def predict():\n","    # Capture image from request\n","    img = imread(io.BytesIO(base64.b64decode(request.form.get('img')[22:])))\n","    img = transform.resize(img, (28, 28))\n","    img = img[:, :, 0] * 255\n","\n","    # Predict based on input\n","    pred = model.predict([img.reshape(784)]).argmax(axis=1)[0].item()\n","    return jsonify({'result': pred})\n","\n","app.run()"]}],"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"name":"Create and Deploy Model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}